version: '3.8'

services:
  nginx:
    container_name: lm_agent_nginx
    tty: true
    image: harbor.tuic.gov.taipei/library/nginx:1.23.1
    restart: always
    volumes:
     - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
     - "80:80"
    networks:
      - shared_network

  web:
    build: 
      context: .
      dockerfile: web_dockerfile
    image: lm-agent/web:v1.0
    container_name: lm_agent_web
    tty: true
    restart: always
    command: streamlit run /web/app.py --server.headless true --server.fileWatcherType none --browser.gatherUsageStats false --server.address 0.0.0.0 --server.port 8502
    ports:
      - "8502:8502"
    networks:
      - shared_network
    volumes:
      - ./web:/web

  process:
    build: 
      context: .
      dockerfile: process_dockerfile
    image: lm-agent/process:v1.0
    container_name: lm_agent_process
    tty: true
    command: gunicorn -w 1 --threads 1 -t 300 -b 0.0.0.0:5010 --chdir /process app:app
    restart: always
    ports:
      - "5010:5010"
    networks:
      - shared_network
    volumes:
      - ./web/DOCUMENT:/process/DOCUMENT
      - ./process:/process

  agent:
    build: 
      context: .
      dockerfile: agent_dockerfile
    image: lm-agent/agent:v1.1
    container_name: lm_agent_agent
    tty: true
    command: gunicorn -w 1 --threads 1 -t 300 -b 0.0.0.0:5020 --chdir /agent app:app
    restart: always
    ports:
      - "5020:5020"
    networks:
      - shared_network
    volumes:
      - ./web/DOCUMENT:/agent/DOCUMENT
      - ./agent:/agent
      - ./pretrained_model/LLM:/pretrained_model/LLM
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  retrieve:
    build: 
      context: .
      dockerfile: retrieve_dockerfile
    image: harbor.tuic.gov.taipei/lm-agent/retrieve:v1.2
    container_name: lm_agent_retrieve
    tty: true
    command: gunicorn -w 1 --threads 1 -t 300 -b 0.0.0.0:5030 --chdir /retrieve app:app
    restart: always
    ports:
      - "5030:5030"
    networks:
      - shared_network
    volumes:
      - ./web/DOCUMENT:/retrieve/DOCUMENT
      - ./retrieve:/retrieve
      - ./pretrained_model/embedding:/pretrained_model/embedding
      - ./pretrained_model/text_classification:/pretrained_model/text_classification
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

networks:
  shared_network:
    driver: bridge
